\documentclass[12pt]{article}
% \usepackage[utf8x]{inputenc}

% \usepackage{natbib}

\title{Ethical principles for the application of artificial intelligence (AI) in nuclear medicine}
\date{}
% \author{}

\begin{document}
\maketitle
\noindent
\textbf{\large Abstract}:\\ \\ \Artificial intelligence (AI) in Nuclear Medicine is a game-changing technology that has the potential to
revolutionize clinical and scientific practice. Although artificial intelligence (AI) is not new to nuclear medicine, medical imaging, or medicine in general, recent developments in machine learning (ML) and deep learning (DL)
have accelerated the adoption of novel algorithms. The task of identifying and resolving ethical dilemmas arises
as a result of this development. With the fast adoption of ML and DL in Nuclear Medicine, ethical challenges are
being recognized at the same time as innovation and deployment, yet contingencies and ethical underpinnings
for proactive management are behind. In clinical and research practice, ethical issues are divided into three
categories: data usage, algorithm selection, and deployment strategy. The ethical issues surrounding the use of
AI in Nuclear Medicine are examined in this paper, and 16 ethical principles are offered as a framework for
applying AI principles in Nuclear Medicine
\noindent
\\ \\ \textbf{\large Table of content:}
\\ \\1.Introduction \\ 2.Ethical challenge \\  3.Ethical principles in AI \\  4.Summary of ethical principles \\ 5.Conclusion \\6.Reference \\ \\ \textbf{\large Introduction:} \\ \\ Artificial intelligence (AI) in Nuclear Medicine is a game-changing technology that has the
potential to revolutionize clinical and scientific practice. Although artificial intelligence (AI) is not new to nuclear
medicine, medical imaging, or medicine in general, recent developments in machine learning (ML) and deep
learning (DL) have accelerated the adoption of novel algorithms. The task of identifying and resolving ethical
dilemmas arises as a result of this development. With the fast adoption of ML and DL in Nuclear Medicine, ethical challenges are being recognized at the same time as innovation and deployment, yet contingencies and
ethical underpinnings for proactive management are behind. In clinical and research practice, ethical issues are
divided into three categories: data usage, algorithm selection, and deployment strategy. Artificial intelligence (AI) is a broad phrase that refers to algorithms that are supposed to mimic certain
characteristics of intelligent human behavior, such as pattern recognition, problem solving, and reasoning. In
medical imaging, an artificial neural network (ANN) is an image processing system made up of layers of linked
nodes that imitate the neuronal connections of the human brain. ANNs are algorithms that analyze data and
identify trends or patterns that may be used to make predictions (e.g. classification of disease). A convolutional
neural network (CNN) is a deep learning ANN that uses a convolutional procedure to extract features from an
image, while an ANN usually takes feature data as input. Machine learning (ML) is a kind of AI that applies ML techniques without being explicitly programmed via data
analysis. After learning from human-defined instructional scenarios characteristic of an ANN, ML is often
connected with addressing logic issues. Deep learning (DL) is a sub-type of machine learning (ML) that uses a
number of processing layers (depth) to discover complicated patterns in images, similar to a CNN. Artificial
intelligence (AI) essentially imitates human intellect, but synthetic intelligence (SI) delivers real higher-order
reasoning utilizing technologies such as quantum logic. In general, AI has two sorts of presence in the patient
care experience in healthcare: virtual and physical. Virtual AI solutions are most widely used in Nuclear
Medicine. However, as the area develops, it will be necessary to tackle the ethical issues that come with
physically present AI solutions. AI in Nuclear Medicine and Molecular Imaging ushers in a new age of clinical and scientific capabilities that have
been reengineered and redesigned. AI has the ability to enhance workflow and efficiency while also lowering
costs, improving accuracy, and facilitating research and discovery. This entails a responsibility of care to patients
to ensure that AI-assisted diagnosis or therapy results in the best possible outcomes. The ethical issues that
occur when utilizing human data to construct person-targeted applications are perhaps the most challenging
problem to handle in AI application to Nuclear Medicine. These ethical concerns are divided into three categories: the data utilized, the algorithms employed, and the
way they are used in practice. These three areas in the interplay between ethical and social challenges for AI in
medical imaging are also identified in a white paper from the French radiology community and a joint
declaration from European and North American associations (Fig. 1)\\

\\ \\

\noindent \textbf{\large Ethical challenge:} \\ \\ In imaging, ethics in AI is being learned at the same time as invention and application (6). There is a
responsibility to fully comprehend the technology, its advantages, and threats. Many AI algorithms work in a
"black box" setting, which means that the underlying stages in the analysis aren't visible. In the face of fast
changing technology, the inability to attain profound comprehension poses a huge ethical dilemma. AI is
confronted with the fundamental ethical issues of autonomy, beneficence, fairness, and knowledge respect. The
distinction between data privacy and confidentiality is a critical idea that occurs from the early processing of
data. Confidentiality refers to the obligation of maintaining privacy whereas privacy refers to the control over
personal information. The potential to considerably enhance health and well-being has spurred demand for not
just better (well-labeled) data, but also commercial access to it (6). There is a trade-off between this
beneficence and the potential for maleficence via commercial data exploitation or real damage to patients or
the "common good" (6). Large data sets for training and validation are the cornerstone of ANN capacity. This
necessitates the use of "big data." Data must then be exported to third-party providers in order for ML and DL
algorithms to be commercialized. Whether the data is utilized for training, validation, research, or therapeutic
purposes, privacy and confidentiality concerns include whether the patient is aware that their data is being used, to what degree, and which components of their data are being used (9). Patients should also know who has
access to their information and if (and to what extent) it has been de-identified (9). A patient should be
informed of the possibility for their data to be exploited for financial gain by others, as well as if future
legislative changes could enhance data vulnerability, particularly if there is a risk that the data will be used in a
manner that is damaging to the patient (9). There is still some disagreement regarding who owns patient data
and what can and cannot be done with it. Informed permission, privacy and data protection, ownership,
impartiality, and injustice relating to those who have or lack the means to process the data are five fundamental
characteristics of ethical data management in AI.
\\ Humans anticipate ethical/moral relationships with and with non-human intelligent life forms, as represented in
movies. When dealing with super-logic and human or superior-tohuman intellect (e.g., humanoid, android, etc. ),
it is expected to follow the same social, ethical, and moral standards as humans. Humanoid or android creatures, by extension, should be held to the same standards. In terms of accountability and responsibility, AI is presently
unaccountable. The fuzzy lines between duties will be more questioned in the future if AI and SI learn
unsupervised. Human control of science capable of supremacy over humans, with blurred lines between what is
human, human-like, and non-human, might be regarded here. It's fitting that the name Frankenstein is widely
used, without distinguishing between Dr. Frankenstein and Frankenstein's monster. Is it a matter of awareness, or is it a matter of perception? If the Turing test is intended to examine AI's capacity to think like a human, we
may be worried about reaching a point when AI passes the Turing test, but we must also consider the possibility
of SI purposefully failing the Turing test. The slogan of "first, do no harm" applies equally to causing damage by adding AI as it does to causing harm by
removing it, and to causing harm by having inequitable access to it. Patients do, however, have the right to have
their treatment tailored to their cultural or philosophical choices. This might include AI-assisted healthcare, but
it should be distinct from the right to have a human physician make decisions. Is it possible to discriminate
against AI or SI? Given the debate above about societal norms, would declining to accept treatment from an AI- /SI-based system based on those grounds alone be any different from rejecting care from a healthcare
practitioner based on their gender or ethnicity? Such concerns must be taken into account.
Inadequate representation of a certain population (e.g., a minority, a vulnerable group, a pathological subtype, etc.) in the training and validation data may cause bias and inaccuracy in predictions, as well as contribute to
the worsening of the health equity gap. This necessitates a few crucial considerations. To begin, one must
understand the training data in relation to the data being input before using an AI system. Second, while
analyzing the output of an algorithm, ecological validity must be taken into account. Finally, algorithm currency
must be maintained to guarantee that prior training data is still relevant for today's data. Finally, when there is a
mismatch between training data and the equipment utilized for real patient data, technology-based bias or
error should be taken into account. This is particularly essential since the neural network function is sometimes
compared to a magician's box, in which we can see what goes in and what comes out but have no idea what
transpires within. Indeed, the genuine magic may be found beyond the confines of the box. Transparency,
justification, and knowledge sharing are all ethical concerns. The area of operation and criteria associated with
unsupervised learning, in particular, are not established by the users, but rather retrieved from the data itself. The capacity to audit this process is crucial for instilling trust in AI outputs, improving AI algorithm quality
assurance, and enabling human learning from AI.
In the context of Nuclear Medicine, considerable thought should be given to AI's disruptive character in terms of
human interactions (staff/staff and staff/patients), health inequities (positive or negative), decision-making
(human, AI, or hybrid), and regulation. Furthermore, major ethical and social issues for AI usage in Nuclear
Medicine include data use, storage, and sharing, algorithm openness and trustworthiness, and need (medical
benefit and patient preferences). These are mostly dismantled and encapsulated in the ethical standards listed
below.
\\ 


\\ \noindent
\\ \textbf{\large summary of ethical principles:}\\ \\

\noindent Beneficence \\ \\
AI/SI solutions should be conceived and executed for the greater good, with some value to humans. Non- maleficence When it comes to building and deploying AI/SI solutions, results, care, and treatment (including
costs) should not be compromised. Justice and fairness Processes should be in place for designing and
implementing AI/SI solutions to guarantee that algorithms treat all patients fairly and equally.\\ \\Safety\\ \\
Prioritize preserving and presenting proof of patient safety and quality of care while building and deploying AI/SI
systems. To securely incorporate AI/SI technologies into their practices, healthcare practitioners must be
adequately taught and equipped.\\\\ Reliability\\\\
When AI/SI solutions are adopted, they must be designed to be dependable and repeatable, including ecological
validity. Methods for quality assurance and performance assessment should be in place for AI/SI mechanisms. \\\\Security\\\\
All data must be kept and transported securely within the scope of regulatory regulations while creating and
implementing AI/SI systems. Without patient agreement and ethical clearance, data should not be moved
beyond the physical/electronic borders of the healthcare provider. \\\\Confidentiality and privacy\\\\
AI/SI solutions should be developed and implemented in such a way that all data may be de-identified, while
also protecting privacy and confidentiality for large data, allowing cross-institutional cooperation, and allowing
commercial use of AI algorithms. Bias Reduction (Mitigation of Bias)
When it comes to designing and implementing AI/SI solutions, rigorous, evidence-based clinical trials must be
used, the data used for algorithm training and validation must be transparently valid for target populations, and
all limitations and potential bias must be disclosed.
8
\\ \\Transparency and visibility are important.\\\\ The usage of, dependence on, and input from AI/SI solutions, as well as how predictions are convolved in the
algorithm (magician's box), should be planned and executed to give transparency to patients and service
customers. Patients must keep their autonomy in order to comprehend how AI/SI technologies are employed in
their treatment and decision-making. \\\\Comprehensibility and explainability\\\\
Any influence on patient care, diagnosis, or treatment must be acknowledged and properly explainable/justified
when creating and deploying AI/SI systems. AI/SI systems should be built in such a way that they can explain
their thinking and have their outputs interpreted by humans.\\\\ Human values are important\\\\. Wherever possible, a human-in-the-loop process should be incorporated into AI/SI solutions to apply
humanitarian values, accommodate patient values and preferences (including social and cultural norms), and
augment AI/SI predictions. \\\\Self-determination, judgment, and decision-making\\\\
A human-in-the-loop process must be incorporated when designing and implementing AI/SI solutions to ensure
that judgment and decision-making in relation to patient care takes into account the patient's presentation, history, findings, and preferences after a conversation between the patient and the healthcare provider. \\\\Collegiality\\\\
Through interdisciplinary collegiality, cooperation, and using the unique competencies of team members in the
AI/SI pipeline, AI/SI solutions should be conceived and deployed to optimize results. \\\\Accountability\\\\
Prior to developing AI/SI solutions, acknowledgement of shared responsibility among stakeholders must be
established and recorded; accountability should not be placed only on the end user interpreting the AI result. Governance
To guarantee compliance with ethical principles, legal regulations, and professional standards, AI/SI solutions
should be conceived and deployed under an overall governance structure.\\\\
Inclusiveness\\\\
When building and implementing AI/SI solutions, all stakeholders should be included and empowered, and, in
the event of disruptive technologies, the effect or displacement of labor should be minimized\\ \\ 



% To change the title from References to Bibliography:
% \renewcommand\refname{}

% \bibliographystyle{plainnat} % or try abbrvnat or unsrtnat
% \bibliography{} % refers to example.bib

\end{document}
